---
title: "exp_19"
author: "Mary English"
date: "2/10/2020"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dada2)
path <- "~/Documents/Oyster_Project/sequencing_feb_2020/fastq_files/exp_19/"
```
\
```{r}
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))

```
\
```{r}
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)

```
\
```{r}
plotQualityProfile(fnFs[1:2])
```
\
Fwd drops off at about 240\
```{r}
plotQualityProfile(fnRs[1:2])
```
\
oof jesus um maybe 140?\
```{r}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```
\
```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs,
                     truncLen=c(240,140),
                     maxN=0,
                     maxEE=c(2,2),
                     truncQ=2,
                     rm.phix=TRUE,
                     compress=TRUE,
                     multithread=TRUE)
```
\
learn errors\
```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)
```
\
```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
```
\
```{r}
dadaFs[[1]] # 116 variants
```
\
merge forward and reverse reads\
```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
```
\
make sequence table\
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # 28 x 275. 28 samples; so we lost 1. rip
table(nchar(getSequences(seqtab)))
```
\
These are all very close, not going to remove any.\
Remove bimeras\
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim) # no chimeras
```
\
Track filtering.\
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
write.csv(track, file = "~/Documents/Oyster_Project/sequencing_feb_2020/fastq_files/exp_19/exp_19_filter_track.csv")
```
\
Based on these numbers, I removed samples with <1000 "final" (nonchim) reads. I also removed these from the corresponding metadata table.\
```{r}
exp_19_asv <- seqtab.nochim
dim(exp_19_asv) # 28 x 275
exp_19_asv_filt <- exp_19_asv[-c(3,4,10,13,14,18,20,21,25,27),]
dim(exp_19_asv_filt) # 18 x 275, 18 samples.
write.csv(exp_19_asv_filt, file = "~/Documents/Oyster_Project/sequencing_feb_2020/fastq_files/exp_19/exp_19_asv_filt.csv")
```
\
Assign taxonomy.\
```{r}
exp_19_taxa_filt <- assignTaxonomy(exp_19_asv_filt, "~/Documents/Oyster_Project/sequencing_feb_2020/fastq_files/exp_18/silva_nr_v132_train_set.fa.gz", multithread=TRUE, tryRC = TRUE)
write.csv(exp_19_taxa_filt, file =  "~/Documents/Oyster_Project/sequencing_feb_2020/fastq_files/exp_19/exp_19_taxa_filt.csv")
```
\
If taxonomy only assigns to kingdom level, try this from https://github.com/benjjneb/dada2/issues/192: 
tax <- assignTaxonomy(dada2:::rc(getSequences(st)), ref.file))\
\
Remove mitochondria and chloroplasts.\
```{r}
library(BiocGenerics)
library(lessR)
reduce_taxa <- apply(exp_19_taxa_filt, 1, function(r) any(r %in% c("Chloroplast", "Mitochondria")))
dim(exp_19_asv_filt) # 18 x 275
exp_19_asv_filt_reduc <- exp_19_asv_filt[,!reduce_taxa]
dim(exp_19_asv_filt_reduc) # 18 x 271
exp_19_asv_filt_reduc <- t(exp_19_asv_filt_reduc)
dim(exp_19_asv_filt_reduc) # 271 x 18
```
\
So there are 4 mitochondria and chloroplasts in these reads.\
Remove from taxa table.\
```{r}
dim(exp_19_taxa_filt) # 275 x 6
exp_19_taxa_filt_reduc <- exp_19_taxa_filt[!reduce_taxa,]
dim(exp_19_taxa_filt_reduc) # 271 x 6
```
\
Start writing fasta -- make 'seqs' BEFORE changing to asvs\
```{r}
seqs <- rownames(exp_19_asv_filt_reduc)
```
\
Change sequences to "asv001" etc. in taxa and asv tables.\
```{r}
asvs <- to("asv", nrow(exp_19_taxa_filt_reduc))
rownames(exp_19_taxa_filt_reduc) <- asvs
rownames(exp_19_asv_filt_reduc) <- asvs
```
\
Rewrite asv and taxa tables after the reduction\
```{r}
write.csv(exp_19_asv_filt_reduc, file = "~/Documents/Oyster_Project/sequencing_feb_2020/fastq_files/exp_19/exp_19_asv_filt_reduc.csv")
write.csv(exp_19_taxa_filt_reduc, file =  "~/Documents/Oyster_Project/sequencing_feb_2020/fastq_files/exp_19/exp_19_taxa_filt_reduc.csv")
```
\
Finish writing fasta of asvs\
```{r}
library(Biostrings)
seqs <- DNAStringSet(seqs)
names(seqs) <- asvs
writeXStringSet(x = seqs, filepath = "~/Documents/Oyster_Project/sequencing_feb_2020/fastq_files/exp_19/exp_19_filt_reduc_seqs.fa")
```
\
<mothur>\
align.seqs(fasta=exp_19_filt_reduc_seqs.fa, reference=/nfs0/Mueller_Lab/sequence_databases/16S_db/silva/silva.nr_v132.align, flip=t, processors=48)\
filter.seqs(fasta=exp_19_filt_reduc_seqs.align, processors=20)\
exit\
\
FastTreeMP -gtr -nt -log exp_19_filt_reduc_seqs.filter.log exp_19_filt_reduc_seqs.filter.fasta > exp_19_filt_reduc_seqs.filter.tre\
/local/cluster/mueller/scripts/Genomics/stat/reroot.pl -midpoint < exp_19_filt_reduc_seqs.filter.tre > exp_19_filt_reduc_seqs.filter.midroot.tre\

tree file: exp_19_filt_reduc_seqs.filter.midroot.tre\
fasta file: exp_19_filt_reduc_seqs.filter.fasta\
Load tree\
```{r}
library(ape)
exp_19_tree <- read.tree(file = "~/Documents/Oyster_Project/sequencing_feb_2020/fastq_files/exp_19/exp_19_filt_reduc_seqs.filter.midroot.tre")
plot(exp_19_tree)
```
\
Load fasta file\
```{r}
exp_19_fasta <- readDNAStringSet("~/Documents/Oyster_Project/sequencing_feb_2020/fastq_files/exp_19/exp_19_filt_reduc_seqs.filter.fasta")
```
\
Handoff to phyloseq\
```{r}
library(phyloseq)
library(ggplot2)
```
\
Start organizing the different tables needed for phyloseq.\
```{r}
meta_19 <- read.table("~/Documents/Oyster_Project/sequencing_feb_2020/fastq_files/exp_19/exp_19_metadata.csv", 
                      sep = ",", header = TRUE, row.names = 1)
taxa_19 <- as.matrix(read.table("~/Documents/Oyster_Project/sequencing_feb_2020/fastq_files/exp_19/exp_19_taxa_filt_reduc.csv", 
                                sep = ",", header = TRUE, row.names = 1))
asv_19 <- as.matrix(read.table("~/Documents/Oyster_Project/sequencing_feb_2020/fastq_files/exp_19/exp_19_asv_filt_reduc.csv", 
                               sep = ",", header = TRUE, row.names = 1))
```
\
Build phyloseq object\
```{r}
exp_19_phylo <- phyloseq(otu_table(asv_19, taxa_are_rows = TRUE),
                         sample_data(meta_19),
                         tax_table(taxa_19),
                         phy_tree(exp_19_tree),
                         refseq(exp_19_fasta))
```
\
Prune taxa that = 0\
```{r}
exp_19_phylo_sum <- prune_taxa(taxa_sums(exp_19_phylo) > 0, exp_19_phylo)
```
\
Plot beta diversity - weighted UNIFRAC\
```{r}
exp_19_phylo_sum_wuni <- ordinate(exp_19_phylo_sum, "PCoA", "unifrac", weighted=TRUE)
exp_19_phylo_sum_wuni_plot <- plot_ordination(exp_19_phylo_sum, exp_19_phylo_sum_wuni, 
                                              color = "Treatment",
                                              title = "Exp 19 larval microbiome ordination plot (Weighted UNIFRAC)")
exp_19_phylo_sum_wuni_plot + geom_point(size = 6)
```
\
Plot beta diversity - unweighted UNIFRAC\
```{r}
exp_19_phylo_sum_uni <- ordinate(exp_19_phylo_sum, "PCoA", "unifrac", weighted= FALSE)
exp_19_phylo_sum_uni_plot <- plot_ordination(exp_19_phylo_sum, exp_19_phylo_sum_uni, 
                                             color = "Treatment", 
                                             title = "Exp 19 larval microbiome ordination plot (Unweighted UNIFRAC)")
exp_19_phylo_sum_uni_plot + geom_point(size = 6)
```
\
\
\
\
To-do later
\
Calculate weighted unifrac beta diversity. Do UNIFRAC separate for use in adonis2.
```{r}
exp_19_phylo_sum_wunidist <- UniFrac(exp_19_phylo_sum, weighted = TRUE, normalized=TRUE, parallel=TRUE, fast=TRUE)

```

